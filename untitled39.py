# -*- coding: utf-8 -*-
"""Untitled39.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BPe5hI_VDVgSenMLDG6OEDtOx-Ub-XY_
"""

import streamlit as st
import joblib
import pandas as pd
import numpy as np
import sklearn
from sklearn.compose import _column_transformer # Import the parent module

# --- Workaround for Version Mismatch ---
# The error 'Can't get attribute '_RemainderColsList'' means the version used
# to save the model is different from the version used to load it.
# This line attempts to define the missing class/attribute if it doesn't exist,
# which can sometimes fix deployment issues, especially on services like Streamlit Community Cloud.
try:
    # Check if the attribute exists; if not, defining it might fix the loading issue
    if not hasattr(_column_transformer, '_RemainderColsList'):
        class RemainderColsList(list):
            """Placeholder class to satisfy old joblib files."""
            pass
        # Dynamically add the missing class to the module namespace
        _column_transformer._RemainderColsList = RemainderColsList
        st.info("Applying scikit-learn version mismatch workaround...")
except Exception:
    pass # Ignore if this fails, the error might be something else

# --- Configuration based on the loaded model structure ---

# Features identified from the ColumnTransformer's 'num' and 'cat' steps
NUM_FEATURES = ['temperature', 'humidity', 'rainfall', 'soil_pH']  #
CAT_FEATURES = [] # The 'cat' transformer had no explicit features in the index array [cite: 2]
# Placeholder for the classes the model predicts (adjust if you know the real names)
CLASSES = ['Disease A', 'Disease B', 'Disease C']

# --- Model Loading Function ---

@st.cache_resource
def load_model(file_path):
    """Loads the scikit-learn pipeline using joblib."""
    try:
        pipeline = joblib.load(file_path)
        # Check if the LogisticRegression model has classes_
        if hasattr(pipeline.named_steps['model'], 'classes_'):
            global CLASSES
            # The classes_ object is a numpy array of dtype O8 (object/string)
            CLASSES = pipeline.named_steps['model'].classes_.tolist()
            st.success(f"Model loaded successfully! Detected classes: {', '.join(CLASSES)}")
        else:
            st.success("Model loaded successfully!")
        return pipeline
    except Exception as e:
        st.error(f"Error loading the model: **{e}**")
        st.warning("This is likely a scikit-learn version mismatch. Check your installed version against **1.6.1**.")
        st.stop()

# --- Main Streamlit Application ---

def main():
    st.set_page_config(page_title="Plant Disease Classifier")
    st.title("ðŸŒ± Plant Disease Classification App")
    st.markdown(f"Using scikit-learn version **{sklearn.__version__}** to load model trained with **~1.6.1**.")
    st.markdown("Enter the environmental conditions to predict the likely plant disease.")

    # 1. Load the model
    MODEL_PATH = 'trained_model.joblib'
    model_pipeline = load_model(MODEL_PATH)

    # 2. Input Fields for Features
    st.header("Environmental Inputs")

    # --- Numerical Inputs ---
    with st.container():
        col1, col2 = st.columns(2)

        with col1:
            temperature = st.number_input(
                "Temperature (Â°C)",
                min_value=0.0,
                max_value=50.0,
                value=25.0,
                step=0.1
            )

            rainfall = st.number_input(
                "Rainfall (mm)",
                min_value=0.0,
                max_value=1000.0,
                value=50.0,
                step=1.0
            )

        with col2:
            humidity = st.number_input(
                "Humidity (%)",
                min_value=0.0,
                max_value=100.0,
                value=60.0,
                step=0.1
            )

            soil_pH = st.number_input(
                "Soil pH",
                min_value=3.0,
                max_value=9.0,
                value=6.5,
                step=0.01
            )

    # --- Categorical Inputs (if any are added later) ---
    # Add input fields for CAT_FEATURES here if you extend the model


    # 3. Prediction Button
    if st.button("Predict Disease"):
        # 4. Create DataFrame for Prediction
        # Must match the column names and order used during training (NUM_FEATURES)
        input_data = pd.DataFrame([{
            'temperature': temperature,
            'humidity': humidity,
            'rainfall': rainfall,
            'soil_pH': soil_pH,
        }])

        st.subheader("Prediction Results")

        # 5. Make Prediction (Probability and Class)
        try:
            # Predict the class
            prediction = model_pipeline.predict(input_data)[0]

            # Predict the probabilities for all classes
            probabilities = model_pipeline.predict_proba(input_data)[0]

            # Find the most likely class and its probability
            predicted_class_index = np.argmax(probabilities)
            predicted_class_name = CLASSES[predicted_class_index]
            predicted_prob = probabilities[predicted_class_index]

            st.success(f"### Predicted Disease: **{predicted_class_name}**")
            st.info(f"Confidence: **{predicted_prob:.2f}**")

            # 6. Display all probabilities
            st.markdown("---")
            st.write("#### All Disease Probabilities:")
            prob_df = pd.DataFrame({
                'Disease': CLASSES,
                'Probability': probabilities
            }).sort_values(by='Probability', ascending=False).reset_index(drop=True)

            # Use Streamlit's data rendering for clarity
            st.dataframe(prob_df, use_container_width=True, hide_index=True)

        except Exception as e:
            st.error(f"An error occurred during prediction: {e}")
            st.warning("The model may have failed to process the input data.")

if __name__ == '__main__':
    main()